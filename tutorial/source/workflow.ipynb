{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for High-Dimensional Models\n",
    "\n",
    "This notebook demonstrates a workflow for incrementally building pipelines to analyze high-dimensional data in Pyro. This tutorial assumes the reader is familiar with Pyro [models](http://pyro.ai/examples/intro_part_i.html), [inference](http://pyro.ai/examples/intro_part_ii.html), and [SVI](http://pyro.ai/examples/svi_part_i.html), and is aware of popular Bayesian workflows such as ([Gelman et al. 2020](https://arxiv.org/abs/2011.01808)).\n",
    "\n",
    "#### Summary\n",
    "\n",
    "Incrementally build a pipeline that includes some of the following steps:\n",
    "1. Clean the data.\n",
    "2. Create a generative model.\n",
    "3. Create an [initialization](https://docs.pyro.ai/en/dev/infer.autoguide.html#module-pyro.infer.autoguide.initialization) heuristic.\n",
    "4. Sanity check point estimates using MAP inference ([AutoDelta](https://docs.pyro.ai/en/dev/infer.autoguide.html#autodelta)).\n",
    "5. Sanity check uncertainty using mean-field inference ([AutoNormal](https://docs.pyro.ai/en/dev/infer.autoguide.html#autonormal)).\n",
    "6. [Reparameterize](https://docs.pyro.ai/en/dev/infer.reparam.html) the model to improve geometry.\n",
    "7. Customize the variational family.\n",
    "8. Draw high-quality posterior samples via variationally preconditioned [NUTS](https://docs.pyro.ai/en/dev/mcmc.html#nuts).\n",
    "\n",
    "After each step, validate your results. If validation fails, backtrack and modify one of the previous steps.\n",
    "\n",
    "#### Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Consider the problem of sampling from the posterior of a probabilistic model with 100k or more continuous latent variables, but whose data fits entirely in memory.\n",
    "Inference in such high-dimensional models can be challenging even when posteriors are known to be unimodal or even log-convex, due to strong correlations among latent variables.\n",
    "\n",
    "To perform inference in such models in Pyro, we have evolved a workflow ([Gelman et al. 2020](https://arxiv.org/abs/2011.01808)) to incrementally build data analysis pipelines combining variational inference, MCMC, reparameterization effects, and ad-hoc initialization strategies.\n",
    "Our workflow is summarized as a sequence of steps, where validation after any step might suggest backtracking to change design decisions at a previous step. (This workflow omits explicit steps for validation because in our experience validation is much more problem-specific than the other steps, and because some sort of validation follows each step.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow steps\n",
    "\n",
    "### Clean the data\n",
    "\n",
    "This first step of the Bayesian workflow is notable in that failures at later steps often indicate errors in data processing, so we must often return here to e.g. remove mis-coded data or fix units errors.\n",
    "Pytorch is great for data cleaning because it is fast, easily handles large tensors, and offers easy serialization via [torch.save()]() and [torch.load()]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a generative model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an initialization heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check point estimates using MAP inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check uncertainty using mean field variational inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reparametrize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize the variational family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw high-quality samples using NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
